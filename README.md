# Описание модели для Benchmark

 семейства VLLM-моделей `Qwen2-VL`.

Материалы о семействе VLLM-моделей:
* [ссылка на GitHub](https://github.com/QwenLM/Qwen2-VL) 
* [ссылка на блог](https://qwenlm.github.io/blog/qwen2-vl/)
* [ссылка на научную статью](https://arxiv.org/pdf/2409.12191)

Я исследовал возможности небольших моделей, которые умещаются на 1 GPU и имеют лицензию Apache-2.0:
* Qwen2-VL-7B-Instruct ([ссылка на HuggingFace](https://huggingface.co/Qwen/Qwen2-VL-7B-Instruct))
* Qwen2-VL-2B-Instruct ([ссылка на HuggingFace](https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct))

# Docker контейнер модели

Поддерживаются модели:

P.S. Укажите одно из следующих названий при инициализации класса Qwen2VL_model(model_name="Qwen2-VL-2B-Instruct")

2B-варианты:
* Qwen2-VL-2B-Instruct
* Qwen2-VL-2B-Instruct-GPTQ-Int4

7B-варианты:
* Qwen2-VL-2B-Instruct

## Build Docker image

Для сборки `Docker image` выполним команду:
```
docker build -t ghcr.io/vlmhyperbenchteam/qwen2-vl:ubuntu22.04-cu124-torch2.4.0_v0.1.0 -f docker/Dockerfile-cu124 .
```

## Run Docker Container

Для запуска `Docker Container` выполним команду:
```
docker run \
    --gpus all \
    -it \
    -v .:/workspace \
    ghcr.io/vlmhyperbenchteam/qwen2-vl:ubuntu22.04-cu124-torch2.4.0_v0.1.0
```

Нам откроется терминал внутри `Docker Container`.

Для запуска предсказаний выполним в нем команду:
```
cd cd workspace
python run_predict.py
```

# Ключевые особенности моделей Qwen2-VL

1. Открытая лицензия - Apache-2.0 (Qwen2-VL-2B, Qwen2-VL-7B)
2. SoTA в понимании изображений и видео ([ссылка](https://github.com/QwenLM/Qwen2-VL#image-benchmarks), [демо  возможностей ссылка](https://qwenlm.github.io/blog/qwen2-vl/#model-capabilities))
3. Старшая модель превосходит GPT4o, Claude 3.5 Sonnet по многим бенчмаркам([ссылка](https://qwenlm.github.io/blog/qwen2-vl/#performance)).

 2B и 7B модели имеют почти такой же уровень точности на документах. Отлично подходят на роль локальной GPT4o .
* Qwen2-VL-2B занимает всего 6 Гб GPU RAM
* Qwen2-VL-7B занимает всего 17 Гб GPU RAM

4. Понимает длинный контекст, например многостраничный документ или видео 20 минут длинной.
5. Понимает много языков(может как считывать с их картинок, так и общается на них) ([ссылка на бенчмарк](https://github.com/QwenLM/Qwen2-VL#multilingual-benchmarks), [ссылка на пример](https://qwenlm.github.io/blog/qwen2-vl/#model-capabilities)):

Основные:
* EN – English (английский)
* ZH – Chinese (китайский)

На очень хорошем уровне:
* RU – Russian (русский)
* AR – Arabic (арабский)
* DE – German (немецкий)
* FR – French (французский)
* IT – Italian (итальянский)
* JA – Japanese (японский)
* KO – Korean (корейский)
* TH – Thai (тайский)
* VI – Vietnamese (вьетнамский)

6. Multi image inference - отвечает на вопрос просматривая сразу несколько сканов страниц длинного документа.
7. Регулируемый вход размера картинки.
* Модель может работать с картинками от 256 до 50176 пикселов.
* По умолчанию принимает документ в исходном разрешении а не сжимает его как все модели.
* Благодаря этому видит мельчащие подробности в документе, которые не видят другие модели из за сжатия картинки на входе.
* Для стабилизации объемов потребляемой памяти API модели позволяет указать диапазон разрешений входных сканов документов до которого они будут сжиматься.

8. Есть квантованные версии моделей ([ссылка](https://github.com/QwenLM/Qwen2-VL#performance-of-quantized-models)).

Они работают еще быстрее и потребляю меньше памяти. По метрикам ответов на датасете для оценивания ответов на вопросы на документах `DocVQA` проседают не так сильно.

9. Довольно быстрые для LLM ([ссылка](https://github.com/QwenLM/Qwen2-VL#speed-benchmark))
10. Поддерживают `Flash attention 2` для доп. ускорения инференса.
11. Есть инструкции по fine tuning и последующей квантизации полученных моделей.
12. Batch inference - предусмотрен.
13. Интегрирована с `HaggingFace` и `vLLM`.

Кроме того:
1.  Понимает диаграммы, графики, интерфейсы (Кажется подойдет и для `NLP`-кейса)
2.  Понимает математику
3.  Умеет анализировать видео по кадрам длинной до 20 минут.

 Может обобщать видеоконтент, отвечать на связанные с ним вопросы и поддерживать непрерывный диалог в режиме реального времени, предлагая поддержку в режиме реального времени в чате. Эта функциональность позволяет ему выступать в роли персонального помощника, помогая пользователям, предоставляя информацию, полученную непосредственно из видеоконтента.

# Результаты теста модели Qwen2-VL-7B-Instruct:
Для получения результатов выполняем:
```
python run_predict.py
```

## Пример счета на оплату:

Приведен пример синтетического документа, форма счета-фактуры найдена в Интернет.
Заполнена на основе генератора случайных чисел и не является реальным счетом на оплату.

![schet_na_oplatu](example_docs/1.png)

### вопросы по данному документу и ответы модели на них

Question:
```
Опиши документ.
```
  
Answer: 
```
Документ представляет собой счет-фактуру (СЧЕТ-ФАКТУРА) от компании "Татэнерго" от 28 сентября 2010 года. 

В документе указаны следующие сведения:

- Продавец: Татэнерго
- Адрес продавца: 189569, к. Красная Поляна, пер. Севастопольский, д. 2/4
- ИНН/КПП продавца: 247899609419/199345731
- Грузоотправитель и его адрес: 189569, к. Красная Поляна, пер. Севастопольский, д. 2/4
- Грузополучатель и его адрес: 165596, ст. Раменское, пр. Автомобилистов, д. 930 к. 3
- Покупатель: РАО «Шашков-Меркушев»
- Адрес покупателя: 165596, ст. Раменское, пр. Автомобилистов, д. 930 к. 3
- ИНН/КПП покупателя: 292675119114/189443405
- Валюта: Российский рубль, код 643

Документ содержит следующие товары/услуги:

1. Пастух отдел мрачно. (код 796, шт., 1 шт., 9955 руб., 18% НДС, 1792 руб., 11747 руб.)
2. Возможно теория порода. (код 796, шт., 1 шт., 6742 руб., 18% НДС, 1214 руб., 7956 руб.)
3. Дорогой карандаш миф. (код 796, шт., 4 шт., 3064 руб., 18
```

